{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7226f240",
   "metadata": {},
   "source": [
    "Awesome stuff - Gradio + smolagents - https://www.gradio.app/guides/agents-and-tool-usage\n",
    "\n",
    "The Gradio Chatbot can natively display intermediate thoughts and tool usage in a collapsible accordion next to a chat message. This makes it perfect for creating UIs for LLM agents and chain-of-thought (CoT) or reasoning demos. This guide will show you how to display thoughts and tool usage with gr.Chatbot and gr.ChatInterface.\n",
    "\n",
    "https://huggingface.co/docs/smolagents/index - \n",
    "\n",
    "What is smolagents?\n",
    "\n",
    "smolagents is an open-source Python library designed to make it extremely easy to build and run agents using just a few lines of code.\n",
    "\n",
    "Key features of smolagents include:\n",
    "\n",
    "âœ¨ Simplicity: The logic for agents fits in ~thousand lines of code. We kept abstractions to their minimal shape above raw code!\n",
    "\n",
    "ğŸ§‘â€ğŸ’» First-class support for Code Agents: CodeAgent writes its actions in code (as opposed to â€œagents being used to write codeâ€) to invoke tools or perform computations, enabling natural composability (function nesting, loops, conditionals). To make it secure, we support executing in sandboxed environment via E2B or via Docker.\n",
    "\n",
    "ğŸ“¡ Common Tool-Calling Agent Support: In addition to CodeAgents, ToolCallingAgent supports usual JSON/text-based tool-calling for scenarios where that paradigm is preferred.\n",
    "\n",
    "ğŸ¤— Hub integrations: Seamlessly share and load agents and tools to/from the Hub as Gradio Spaces.\n",
    "\n",
    "ğŸŒ Model-agnostic: Easily integrate any large language model (LLM), whether itâ€™s hosted on the Hub via Inference providers, accessed via APIs such as OpenAI, Anthropic, or many others via LiteLLM integration, or run locally using Transformers or Ollama. Powering an agent with your preferred LLM is straightforward and flexible.\n",
    "\n",
    "ğŸ‘ï¸ Modality-agnostic: Beyond text, agents can handle vision, video, and audio inputs, broadening the range of possible applications. Check out this tutorial for vision.\n",
    "\n",
    "ğŸ› ï¸ Tool-agnostic: You can use tools from any MCP server, from LangChain, you can even use a Hub Space as a tool.\n",
    "\n",
    "ğŸ’» CLI Tools: Comes with command-line utilities (smolagent, webagent) for quickly running agents without writing boilerplate code."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
